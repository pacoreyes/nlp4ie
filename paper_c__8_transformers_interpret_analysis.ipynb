{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T18:31:02.851563Z",
     "start_time": "2024-07-22T18:30:53.610616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: MPS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature     value\n",
      "0       we -0.005611\n",
      "1      are  0.291439\n",
      "2     very  0.267650\n",
      "3        ,  0.146605\n",
      "4     very  0.053275\n",
      "5    tough -0.014060\n",
      "6       on -0.047627\n",
      "7     that  0.065601\n",
      "8        . -0.038670\n",
      "9      and  0.705443\n",
      "10    that  0.227741\n",
      "11      is  0.042040\n",
      "12   going  0.016047\n",
      "13      to  0.147235\n",
      "14  remain -0.082753\n",
      "15   tough -0.031289\n",
      "16       ,  0.191310\n",
      "17      or  0.274871\n",
      "18    even  0.310626\n",
      "19   tough -0.032467\n",
      "20    ##er  0.140080\n",
      "21       . -0.020853\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>not_continue</b></text></td><td><text style=\"padding-right:2em\"><b>continue (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>continue</b></text></td><td><text style=\"padding-right:2em\"><b>2.61</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> are                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> very                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> very                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tough                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> on                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> that                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> going                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> remain                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tough                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> or                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> even                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> tough                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##er                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: not_continue\n",
      "\n",
      "S1: We are very, very tough on that.\n",
      "S2: And that is going to remain tough, or even tougher.\n",
      "\n",
      "ID: 102\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers_interpret import PairwiseSequenceClassificationExplainer\n",
    "\n",
    "from db import spreadsheet_7\n",
    "from lib.utils import read_from_google_sheet\n",
    "\n",
    "# Set display options to ensure all rows and columns are displayed\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "REVERSED_LABEL_MAP = {0: \"continue\", 1: \"not_continue\"}\n",
    "\n",
    "def get_device():\n",
    "  \"\"\"Returns the appropriate device available in the system: CUDA, MPS, or CPU\"\"\"\n",
    "  if torch.backends.mps.is_available():\n",
    "    return torch.device(\"mps\")\n",
    "  elif torch.cuda.is_available():\n",
    "    return torch.device(\"cuda\")\n",
    "  else:\n",
    "    return torch.device(\"cpu\")\n",
    "  \n",
    "\n",
    "def set_seed(seed_value):\n",
    "  \"\"\"Set seed for reproducibility.\"\"\"\n",
    "  random.seed(seed_value)\n",
    "  np.random.seed(seed_value)\n",
    "  torch.manual_seed(seed_value)\n",
    "  torch.cuda.manual_seed_all(seed_value)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(SEED)\n",
    "\n",
    "# Set device\n",
    "device = get_device()\n",
    "print(f\"\\nUsing device: {str(device).upper()}\\n\")\n",
    "\n",
    "CLASS_NAMES = ['continue', 'not_continue']\n",
    "\n",
    "# Load dataset\n",
    "# not_continue_test_dataset = load_jsonl_file(\"shared_data/topic_boundary_not_continue_class.jsonl\")\n",
    "# continue_test_dataset = load_jsonl_file(\"shared_data/topic_boundary_continue_class.jsonl\")\n",
    "\n",
    "DATASET = read_from_google_sheet(spreadsheet_7, \"test_dataset\")\n",
    "\n",
    "# Initialize constants\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "MODEL_PATH = 'models/3/TopicContinuityBERT.pth'\n",
    "\n",
    "# Initialize tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"models/3/tokenizer\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=2)\n",
    "\n",
    "# Move the model to the device\n",
    "# model = model.to(device)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "# Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Explainer initialization\n",
    "pairwise_explainer = PairwiseSequenceClassificationExplainer(\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    "  custom_labels=CLASS_NAMES,\n",
    "  attribution_type=\"lig\",\n",
    ")\n",
    "\n",
    "# Select a sample from the dataset\n",
    "example = DATASET[101]  # ID - 1 <---------------------------------------------------------\n",
    "\n",
    "text = example[\"text\"]\n",
    "true_label = example[\"label\"]\n",
    "# sentence1, sentence2 = text.split('[SEP]')\n",
    "\n",
    "# sentence1 = sentence1.strip()\n",
    "# sentence2 = sentence2.strip()\n",
    "\n",
    "# sentence1 = \"This would have a similar outcome as the standard deduction I proposed, and I'm open to further discussions about this - about this two options.\"\n",
    "sentence1 = \"We are very, very tough on that.\"\n",
    "sentence2 = \"And that is going to remain tough, or even tougher.\"\n",
    "#sentence2 = \"There's a better way from expanding the government, and that is to reform the Tax Code.\"\n",
    "\n",
    "explanation_data = pairwise_explainer( text1=sentence1, text2=sentence2)  # flip_sign=True,\n",
    "\n",
    "# Remove rows with blank features (\"\")\n",
    "explanation_data = [row for row in explanation_data if row[0] not in [\"[PAD]\", \"[CLS]\", \"[SEP]\"]]\n",
    "# Aggregate subtokens\n",
    "# explanation_data = aggregate_subtokens(explanation_data)\n",
    "\n",
    "df_explanation_data = pd.DataFrame(explanation_data, columns=[\"feature\", \"value\"])\n",
    "\n",
    "print(df_explanation_data)\n",
    "\n",
    "pairwise_explainer.visualize(\"topic_boundary.html\", true_class=true_label)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def preprocess_pairs(_texts, _tokenizer, max_length=512):\n",
    "  \"\"\"Tokenize and preprocess text pairs.\"\"\"\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "\n",
    "  for text in _texts:\n",
    "    # Split the text into two sentences using a delimiter\n",
    "    sentence1, sentence2 = text.split('[SEP]')\n",
    "    encoded_input = _tokenizer.encode(\n",
    "      sentence1.strip(),\n",
    "      sentence2.strip(),\n",
    "      add_special_tokens=True,\n",
    "      max_length=max_length,\n",
    "      truncation=True,\n",
    "      return_tensors='pt'  # Ensure output is in tensor format\n",
    "    )\n",
    "\n",
    "    # Pad the encoded_input to max_length\n",
    "    padded_input = torch.full((1, max_length), _tokenizer.pad_token_id)\n",
    "    padded_input[:, :encoded_input.size(1)] = encoded_input\n",
    "\n",
    "    # Create an attention mask for the non-padded elements\n",
    "    attention_mask = (padded_input != _tokenizer.pad_token_id).int()\n",
    "\n",
    "    input_ids.append(padded_input)\n",
    "    attention_masks.append(attention_mask)\n",
    "\n",
    "  # Concatenate all input_ids and attention_masks\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "  return input_ids, attention_masks\n",
    "\n",
    "\n",
    "def classify_sentences(_model, _sentence_pairs, _tokenizer, _device):\n",
    "  # model.eval()  # Ensure the model is in eval mode\n",
    "  input_ids, attention_masks = preprocess_pairs(_sentence_pairs, _tokenizer)\n",
    "\n",
    "  # Move tensors to the device where the model is\n",
    "  input_ids = input_ids.to(_device)\n",
    "  attention_masks = attention_masks.to(_device)\n",
    "\n",
    "  with torch.no_grad():  # No need to track gradients for inference\n",
    "    outputs = _model(input_ids, attention_mask=attention_masks)\n",
    "    logits = outputs.logits\n",
    "    _predictions = torch.argmax(logits, dim=-1)  # Get the predicted classes\n",
    "\n",
    "  return _predictions\n",
    "\n",
    "\n",
    "def inference_pair(_sentence_pairs):\n",
    "  predictions = classify_sentences(model, _sentence_pairs, tokenizer, device)\n",
    "  predictions = [REVERSED_LABEL_MAP[p.item()] for p in predictions]\n",
    "  return predictions[0]\n",
    "\n",
    "\n",
    "predictions = classify_sentences(model, [text], tokenizer, device)\n",
    "# print(predictions)\n",
    "\n",
    "# Convert predictions to class names\n",
    "predictions = [REVERSED_LABEL_MAP[p.item()] for p in predictions]\n",
    "print(f\"Predicted class: {predictions[0]}\")\n",
    "\n",
    "#inputs = tokenizer.encode(sentence1, sentence2, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Predict\n",
    "#with torch.no_grad():\n",
    "#  outputs = model(**inputs)\n",
    "\n",
    "# Process the output logits\n",
    "#logits = outputs.logits\n",
    "#predicted_class_id = logits.argmax().item()\n",
    "print()\n",
    "print(f\"S1: {sentence1}\")\n",
    "print(f\"S2: {sentence2}\")\n",
    "print()\n",
    "print(f\"ID: {example['id']}\")\n",
    "\n",
    "# print(f\"Predicted class ID: {predicted_class_id}\")\n",
    "#predicted_class_name = CLASS_NAMES[predicted_class_id]\n",
    "#print(f\"Predicted class: {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3f48406747c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
